{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d105085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:56:13.138937Z",
     "iopub.status.busy": "2025-03-06T12:56:13.138578Z",
     "iopub.status.idle": "2025-03-06T12:56:14.349523Z",
     "shell.execute_reply": "2025-03-06T12:56:14.348432Z"
    },
    "papermill": {
     "duration": 1.217444,
     "end_time": "2025-03-06T12:56:14.351618",
     "exception": false,
     "start_time": "2025-03-06T12:56:13.134174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from git import Repo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import json\n",
    "from kaggle_secrets import UserSecretsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a00fe2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:56:14.358560Z",
     "iopub.status.busy": "2025-03-06T12:56:14.357996Z",
     "iopub.status.idle": "2025-03-06T12:56:14.365822Z",
     "shell.execute_reply": "2025-03-06T12:56:14.364779Z"
    },
    "papermill": {
     "duration": 0.012953,
     "end_time": "2025-03-06T12:56:14.367593",
     "exception": false,
     "start_time": "2025-03-06T12:56:14.354640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(dataFrame):\n",
    "    try:\n",
    "        numeric_cols = dataFrame.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        for column in numeric_cols:\n",
    "            Q1 = dataFrame[column].quantile(0.25)\n",
    "            Q3 = dataFrame[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = max(Q1 - 1.5 * IQR, dataFrame[column].min())\n",
    "            upper_bound = min(Q3 + 1.5 * IQR, dataFrame[column].max())\n",
    "            dataFrame[column] = np.where(dataFrame[column] < lower_bound, lower_bound, dataFrame[column])\n",
    "            dataFrame[column] = np.where(dataFrame[column] > upper_bound, upper_bound, dataFrame[column])\n",
    "            # print(f\"Outliers handled in column: {column}\")\n",
    "        return dataFrame\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to detect outliers in {column}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5a8d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:56:14.374156Z",
     "iopub.status.busy": "2025-03-06T12:56:14.373804Z",
     "iopub.status.idle": "2025-03-06T12:56:14.380993Z",
     "shell.execute_reply": "2025-03-06T12:56:14.379792Z"
    },
    "papermill": {
     "duration": 0.01262,
     "end_time": "2025-03-06T12:56:14.382886",
     "exception": false,
     "start_time": "2025-03-06T12:56:14.370266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FeatureEngineering_File_Extraction(repo_url, kaggle_repo_url, FeatureEngineering_path):\n",
    "    if os.path.exists(kaggle_repo_url):\n",
    "        print(\"Repository already exists locally.\")\n",
    "        repo = Repo(kaggle_repo_url)  \n",
    "        repo.config_writer().set_value(\"user\", \"name\", name).release()\n",
    "        repo.config_writer().set_value(\"user\", \"email\", email).release()\n",
    "        origin = repo.remote(name='origin')  \n",
    "        origin.pull() \n",
    "        print(\"Successfully pulled the latest changes.\")\n",
    "    else:\n",
    "        repo = Repo.clone_from(repo_url, kaggle_repo_url)\n",
    "        repo.config_writer().set_value(\"user\", \"name\", name).release()\n",
    "        repo.config_writer().set_value(\"user\", \"email\", email).release()\n",
    "        print(\"Successfully cloned the repository.\")\n",
    "\n",
    "   \n",
    "    output_files = os.listdir(FeatureEngineering_path)\n",
    "    FeatureEngineering_File = max(\n",
    "        [file for file in output_files if file.startswith(\"FE_\") and file.endswith('records.json')]\n",
    "    )\n",
    "\n",
    "   \n",
    "    FeatureEngineering_File = pd.read_json(os.path.join(FeatureEngineering_path, FeatureEngineering_File))\n",
    "\n",
    "    return FeatureEngineering_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4889f3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:56:14.389454Z",
     "iopub.status.busy": "2025-03-06T12:56:14.389073Z",
     "iopub.status.idle": "2025-03-06T12:56:14.397519Z",
     "shell.execute_reply": "2025-03-06T12:56:14.396171Z"
    },
    "papermill": {
     "duration": 0.013743,
     "end_time": "2025-03-06T12:56:14.399356",
     "exception": false,
     "start_time": "2025-03-06T12:56:14.385613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PushToGithub(filename,destination_path):\n",
    "    try:\n",
    "        if os.path.exists(kaggle_repo_url):\n",
    "            print(\"Already cloned and the repo file exists\")\n",
    "            repo = Repo(kaggle_repo_url)\n",
    "            repo.config_writer().set_value(\"user\", \"name\", name).release()\n",
    "            repo.config_writer().set_value(\"user\", \"email\", email).release()\n",
    "            origin = repo.remote(name='origin')\n",
    "            origin.pull()\n",
    "            print(\"Successfully pulled the git repo before push\")\n",
    "        else:\n",
    "            repo = Repo.clone_from(repo_url, kaggle_repo_url)\n",
    "            repo.config_writer().set_value(\"user\", \"name\", name).release()\n",
    "            repo.config_writer().set_value(\"user\", \"email\", email).release()\n",
    "            print(\"Successfully cloned the git repo\")\n",
    "        \n",
    "        if os.path.exists(destination_path):\n",
    "            shutil.copyfile(f'/kaggle/working/{filename}', f'{destination_path}/{filename}')\n",
    "        else:\n",
    "            os.makedirs(destination_path)\n",
    "            shutil.copyfile(f'/kaggle/working/{filename}', f'{destination_path}/{filename}')\n",
    "        \n",
    "        repo = Repo(kaggle_repo_url)\n",
    "        repo.index.add([f\"{destination_path}/{filename}\"])\n",
    "        timestamp = datetime.now(ist).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        repo.index.commit(f\"{timestamp} Added files from Kaggle notebook, {filename}\")\n",
    "        origin = repo.remote(name=\"origin\")\n",
    "        push_result = origin.push()\n",
    "        \n",
    "        if push_result:\n",
    "            print(\"Output files successfully pushed to GitHub!\")\n",
    "        else:\n",
    "            print(\"Output files pushed to GitHub failed:(\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred at git automation code: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32757c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:56:14.406142Z",
     "iopub.status.busy": "2025-03-06T12:56:14.405799Z",
     "iopub.status.idle": "2025-03-06T12:56:14.413543Z",
     "shell.execute_reply": "2025-03-06T12:56:14.412437Z"
    },
    "papermill": {
     "duration": 0.013262,
     "end_time": "2025-03-06T12:56:14.415367",
     "exception": false,
     "start_time": "2025-03-06T12:56:14.402105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_eda_validation(dataFrame):\n",
    "\n",
    "    report_df = pd.DataFrame({\n",
    "        \"missing_values\": dataFrame.isnull().sum(),\n",
    "        \"duplicates\": [dataFrame.duplicated().sum()] * len(dataFrame.columns),\n",
    "        \"data_types\": dataFrame.dtypes.astype(str),\n",
    "        \"cardinality\": dataFrame.nunique()\n",
    "    }).reset_index().rename(columns={\"index\": \"columns\"})\n",
    "\n",
    "    # Extract inconsistent records for group1\n",
    "    inconsistent_group1 = dataFrame[dataFrame.duplicated(subset=[\"channelId\"], keep=False)][\n",
    "        [\"channelId\", \"channelName\", \"channelCustomUrl\", \"channelGrowthScoreRank\"]]\n",
    "\n",
    "    # Extract inconsistent records for group2\n",
    "    inconsistent_group2 = dataFrame[dataFrame.duplicated(subset=[\"videoId\"], keep=False)][\n",
    "        [\"videoId\", \"videoTitle\", \"videoEngagementScoreRank\"]]\n",
    "    DataFrameHandelledOutliers = detect_outliers_iqr(dataFrame)\n",
    "    report = {\n",
    "        \"Pre_EDA\": report_df.to_dict(orient=\"records\"),\n",
    "        \"inconsistent_records_channelLevel\": inconsistent_group1.to_dict(orient=\"records\"),\n",
    "        \"inconsistent_records_videolevel\": inconsistent_group2.to_dict(orient=\"records\"),\n",
    "        \"Dataframe\": DataFrameHandelledOutliers.to_dict(orient=\"records\")\n",
    "    }\n",
    "    record_count = len(DataFrameHandelledOutliers)\n",
    "    timestamp = datetime.now(ist).strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "    filename = f\"PEDA_{timestamp}_{record_count}_records.json\"\n",
    "\n",
    "    if report[\"Pre_EDA\"]:\n",
    "        with open(filename, \"w\") as json_file:\n",
    "            json.dump(report, json_file, indent=4)\n",
    "        print(f\"DataFrame validation report saved as {filename}\")\n",
    "    else:\n",
    "        print(\"No data to save since empty DataFrame returned.\")\n",
    "\n",
    "    destination_path = '/kaggle/working/DevOps-YouTube-Trends/ExploratoryDataAnalysis/PEDA/Daily'\n",
    "    PushToGithub(filename, destination_path)\n",
    "        \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d46d817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:56:14.421730Z",
     "iopub.status.busy": "2025-03-06T12:56:14.421365Z",
     "iopub.status.idle": "2025-03-06T12:56:14.425945Z",
     "shell.execute_reply": "2025-03-06T12:56:14.424897Z"
    },
    "papermill": {
     "duration": 0.009664,
     "end_time": "2025-03-06T12:56:14.427614",
     "exception": false,
     "start_time": "2025-03-06T12:56:14.417950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(repo_url, kaggle_repo_url, FeatureEngineering_path, ExploratoryDataAnalysis_path):\n",
    "    FeatureEngineering_File = FeatureEngineering_File_Extraction(repo_url, kaggle_repo_url, FeatureEngineering_path)\n",
    "    pre_eda_validation(FeatureEngineering_File)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10073a5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:56:14.434350Z",
     "iopub.status.busy": "2025-03-06T12:56:14.433964Z",
     "iopub.status.idle": "2025-03-06T12:56:20.392411Z",
     "shell.execute_reply": "2025-03-06T12:56:20.390850Z"
    },
    "papermill": {
     "duration": 5.964421,
     "end_time": "2025-03-06T12:56:20.394820",
     "exception": false,
     "start_time": "2025-03-06T12:56:14.430399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cloned the repository.\n",
      "DataFrame validation report saved as PEDA_2025-03-06_18_26_19_403_records.json\n",
      "Already cloned and the repo file exists\n",
      "Successfully pulled the git repo before push\n",
      "Output files successfully pushed to GitHub!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    user_secrets = UserSecretsClient()\n",
    "    secret_value_0 = user_secrets.get_secret(\"EDARepoOwner\")\n",
    "    secret_value_1 = user_secrets.get_secret(\"EDARepoOwnerMail\")\n",
    "    secret_value_2 = user_secrets.get_secret(\"EDARepoURL\")\n",
    "    \n",
    "    name = secret_value_0\n",
    "    email = secret_value_1\n",
    "    repo_url = secret_value_2\n",
    "    \n",
    "    kaggle_repo_url = '/kaggle/working/DevOps-YouTube-Trends'\n",
    "    FeatureEngineering_path = '/kaggle/working/DevOps-YouTube-Trends/FeatureEngineering/Daily'\n",
    "    ExploratoryDataAnalysis_path = '/kaggle/working/DevOps-YouTube-Trends/ExploratoryDataAnalysis'\n",
    "\n",
    "    ist = timezone(\"Asia/Kolkata\")\n",
    "    \n",
    "    main(repo_url, kaggle_repo_url, FeatureEngineering_path, ExploratoryDataAnalysis_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.691316,
   "end_time": "2025-03-06T12:56:21.019326",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-06T12:56:10.328010",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
